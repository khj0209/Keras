{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 기사 분류: 다중 분류 문제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EB%94%A5%EB%9F%AC%EB%8B%9D/) 책의 3장 5절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다.\n",
    "\n",
    "----\n",
    "\n",
    "이전 섹션에서 완전 연결된 신경망을 사용해 벡터 입력을 어떻게 두 개의 클래스로 분류하는지 보았습니다. 두 개 이상의 클래스가 있을 때는 어떻게 해야 할까요?\n",
    "\n",
    "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제입니다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로이터 데이터셋\n",
    "\n",
    "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋입니다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많습니다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n",
    "\n",
    "IMDB와 MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. 한 번 살펴보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 데이터셋에서처럼 num_words=10000 매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한합니다.\n",
    "\n",
    "여기에는 8,982개의 훈련 샘플과 2,246개의 테스트 샘플이 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 리뷰처럼 각 샘플은 정수 리스트입니다(단어 인덱스):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "궁금한 경우를 위해 어떻게 단어로 디코딩하는지 알아보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 6s 11us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "이전의 예제와 동일한 코드를 사용해서 데이터를 벡터로 변환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터 벡터 변환\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터 벡터 변환\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블을 벡터로 바꾸는 방법은 두 가지입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부릅니다. 원-핫 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 레이블 벡터 변환\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# 테스트 레이블 벡터 변환\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성\n",
    "\n",
    "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보입니다. 두 경우 모두 짧은 텍스트를 분류하는 것이죠. 여기에서는 새로운 제약 사항이 추가되었습니다. 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌습니다.\n",
    "\n",
    "이전에 사용했던 것처럼 `Dense` 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있습니다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없습니다. 각 층은 잠재적으로 정보의 병목이 될 수 있습니다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다.\n",
    "\n",
    "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 구조에서 주목해야 할 점이 두 가지 있습니다:\n",
    "\n",
    "* 마지막 `Dense` 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것입니다.\n",
    "* 마지막 층에 `softmax` 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉, 46차원의 출력 벡터를 만들며 `output[i]`는 어떤 샘플이 클래스 `i`에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다.\n",
    "\n",
    "이런 문제에 사용할 최선의 손실 함수는 `categorical_crossentropy`입니다. 이 함수는 두 확률 분포의 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 20번의 에포크로 모델을 훈련시킵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 19:57:29.887705 14212 deprecation.py:323] From C:\\Users\\HyeongJung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0729 19:57:29.955471 14212 deprecation_wrapper.py:119] From C:\\Users\\HyeongJung\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 151us/step - loss: 2.4997 - acc: 0.4899 - val_loss: 1.6813 - val_acc: 0.6480\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 1.3915 - acc: 0.7038 - val_loss: 1.2790 - val_acc: 0.7190\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 104us/step - loss: 1.0487 - acc: 0.7699 - val_loss: 1.1181 - val_acc: 0.7610\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 107us/step - loss: 0.8246 - acc: 0.8282 - val_loss: 1.0217 - val_acc: 0.7760\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.6599 - acc: 0.8637 - val_loss: 0.9688 - val_acc: 0.7970\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.5254 - acc: 0.8931 - val_loss: 0.9200 - val_acc: 0.8090\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.4291 - acc: 0.9118 - val_loss: 0.9108 - val_acc: 0.8030\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 105us/step - loss: 0.3497 - acc: 0.9277 - val_loss: 0.8937 - val_acc: 0.8150\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.2893 - acc: 0.9386 - val_loss: 0.9128 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.2450 - acc: 0.9453 - val_loss: 0.9114 - val_acc: 0.8100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.2102 - acc: 0.9481 - val_loss: 0.9482 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 97us/step - loss: 0.1878 - acc: 0.9528 - val_loss: 0.9613 - val_acc: 0.8040\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.1658 - acc: 0.9529 - val_loss: 0.9926 - val_acc: 0.8010\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 100us/step - loss: 0.1532 - acc: 0.9550 - val_loss: 0.9772 - val_acc: 0.8050\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.1456 - acc: 0.9550 - val_loss: 1.0188 - val_acc: 0.7990\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.1326 - acc: 0.9554 - val_loss: 1.0390 - val_acc: 0.8000\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 0.1255 - acc: 0.9554 - val_loss: 1.0423 - val_acc: 0.7970\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.1170 - acc: 0.9560 - val_loss: 1.0367 - val_acc: 0.8150\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.1157 - acc: 0.9573 - val_loss: 1.0290 - val_acc: 0.8080\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 0.1136 - acc: 0.9582 - val_loss: 1.0496 - val_acc: 0.8030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실과 정확도 곡선을 그려 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 9번째 에포크 이후에 과대적합이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 2.5398 - acc: 0.5226 - val_loss: 1.6733 - val_acc: 0.6570\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 97us/step - loss: 1.3712 - acc: 0.7121 - val_loss: 1.2758 - val_acc: 0.7210\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 1.0136 - acc: 0.7781 - val_loss: 1.1303 - val_acc: 0.7530\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.7976 - acc: 0.8251 - val_loss: 1.0539 - val_acc: 0.7590\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.6393 - acc: 0.8624 - val_loss: 0.9754 - val_acc: 0.7920\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.5124 - acc: 0.8921 - val_loss: 0.9102 - val_acc: 0.8140\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 100us/step - loss: 0.4124 - acc: 0.9139 - val_loss: 0.8932 - val_acc: 0.8210\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 100us/step - loss: 0.3355 - acc: 0.9290 - val_loss: 0.8733 - val_acc: 0.8260\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.2782 - acc: 0.9372 - val_loss: 0.9342 - val_acc: 0.8000\n",
      "2246/2246 [==============================] - 0s 115us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0227517058354665, 0.7756010686194165]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.182546749777382"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델 인스턴스의 `predict` 메서드는 46개 토픽에 대한 확률 분포를 반환합니다. 테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predictions`의 각 항목은 길이가 46인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 벡터의 원소 합은 1입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999976"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 큰 값이 예측 클래스가 됩니다. 즉, 가장 확률이 높은 클래스입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블과 손실을 다루는 다른 방법\n",
    "\n",
    "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 코드 3-21에 사용된 손실 함수 `categorical_crossentropy`는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 `sparse_categorical_crossentropy`를 사용해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 `categorical_crossentropy`와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 충분히 큰 중간층을 두어야 하는 이유\n",
    "\n",
    "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 188us/step - loss: 2.6576 - acc: 0.3773 - val_loss: 1.9682 - val_acc: 0.5280\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 167us/step - loss: 1.6651 - acc: 0.6209 - val_loss: 1.5405 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 166us/step - loss: 1.3324 - acc: 0.6704 - val_loss: 1.3942 - val_acc: 0.6790\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 166us/step - loss: 1.1420 - acc: 0.7268 - val_loss: 1.3264 - val_acc: 0.6960\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 162us/step - loss: 1.0111 - acc: 0.7461 - val_loss: 1.2694 - val_acc: 0.7020\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.9098 - acc: 0.7583 - val_loss: 1.2754 - val_acc: 0.7070\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.8301 - acc: 0.7737 - val_loss: 1.2580 - val_acc: 0.7090\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.7689 - acc: 0.7895 - val_loss: 1.2658 - val_acc: 0.7200\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 156us/step - loss: 0.7125 - acc: 0.8011 - val_loss: 1.2876 - val_acc: 0.7120\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.6615 - acc: 0.8108 - val_loss: 1.3259 - val_acc: 0.7040\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 0.6163 - acc: 0.8207 - val_loss: 1.3525 - val_acc: 0.7140\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 158us/step - loss: 0.5778 - acc: 0.8331 - val_loss: 1.3945 - val_acc: 0.7120\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 0.5401 - acc: 0.8447 - val_loss: 1.4494 - val_acc: 0.7060\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.5080 - acc: 0.8559 - val_loss: 1.4731 - val_acc: 0.7120\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.4765 - acc: 0.8668 - val_loss: 1.5175 - val_acc: 0.7130\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.4480 - acc: 0.8797 - val_loss: 1.5598 - val_acc: 0.7070\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.4242 - acc: 0.8822 - val_loss: 1.6095 - val_acc: 0.7110\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 151us/step - loss: 0.4040 - acc: 0.8923 - val_loss: 1.6388 - val_acc: 0.7090\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 151us/step - loss: 0.3831 - acc: 0.8951 - val_loss: 1.6651 - val_acc: 0.7100\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.3660 - acc: 0.8981 - val_loss: 1.7414 - val_acc: 0.7040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f82b56b38>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 정확도의 최고 값은 약 71%로 8% 정도 감소되었습니다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 실험\n",
    "\n",
    "* 더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
    "* 여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다.\n",
    "\n",
    "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 `Dense` 층의 크기는 N이어야 합니다.\n",
    "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 `softmax` 활성화 함수를 사용해야 합니다.\n",
    "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다.\n",
    "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다.\n",
    "    * 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 `categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "    * 레이블을 정수로 인코딩하고 `sparse_categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "* 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
