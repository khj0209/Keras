{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 리뷰 분류: 이진 분류 예제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EB%94%A5%EB%9F%AC%EB%8B%9D/) 책의 3장 4절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다.\n",
    "\n",
    "----\n",
    "\n",
    "2종 분류 또는 이진 분류는 아마도 가장 널리 적용된 머신 러닝 문제일 것입니다. 이 예제에서 리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정로 분류하는 법을 배우겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 데이터셋\n",
    "\n",
    "인터넷 영화 데이터베이스로부터 가져온 양극단의 리뷰 50,000개로 이루어진 IMDB 데이터셋을 사용하겠습니다. 이 데이터셋은 훈련 데이터 25,000개와 테스트 데이터 25,000개로 나뉘어 있고 각각 50%는 부정, 50%는 긍정 리뷰로 구성되어 있습니다.\n",
    "\n",
    "왜 훈련 데이터와 테스트 데이터를 나눌까요? 같은 데이터에서 머신 러닝 모델을 훈련하고 테스트해서는 절대 안 되기 때문입니다! 모델이 훈련 데이터에서 잘 작동한다는 것이 처음 만난 데이터에서도 잘 동작한다는 것을 보장하지 않습니다. 중요한 것은 새로운 데이터에 대한 모델의 성능입니다(사실 훈련 데이터의 레이블은 이미 알고 있기 때문에 이를 예측하는 모델은 필요하지 않습니다). 예를 들어 모델이 훈련 샘플과 타깃 사이의 매핑을 모두 외워버릴 수 있습니다. 이런 모델은 처음 만나는 데이터에서 타깃을 예측하는 작업에는 쓸모가 없습니다. 다음 장에서 이에 대해 더 자세히 살펴보겠습니다.\n",
    "\n",
    "MNIST 데이터셋처럼 IMDB 데이터셋도 케라스에 포함되어 있습니다. 이 데이터는 전처리되어 있어 각 리뷰(단어 시퀀스)가 숫자 시퀀스로 변환되어 있습니다. 여기서 각 숫자는 사전에 있는 고유한 단어를 나타냅니다.\n",
    "\n",
    "다음 코드는 데이터셋을 로드합니다(처음 실행하면 17MB 정도의 데이터가 컴퓨터에 다운로드됩니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hyeongjung\\anaconda3\\lib\\site-packages (1.16.1)\n",
      "Requirement already up-to-date: numpy==1.16.1 in c:\\users\\hyeongjung\\anaconda3\\lib\\site-packages (1.16.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy \n",
    "! pip install --upgrade numpy==1.16.1\n",
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매개변수 `num_words=10000`은 훈련 데이터에서 가장 자주 나타나는 단어 10,000개만 사용하겠다는 의미입니다. 드물게 나타나는 단어는 무시하겠습니다. 이렇게 하면 적절한 크기의 벡터 데이터를 얻을 수 있습니다.\n",
    "\n",
    "변수 `train_data`와 `test_data`는 리뷰의 목록입니다. 각 리뷰는 단어 인덱스의 리스트입니다(단어 시퀀스가 인코딩된 것입니다). `train_labels`와 `test_labels`는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 자주 등장하는 단어 10,000개로 제한했기 때문에 단어 인덱스는 10,000을 넘지 않습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재미 삼아 이 리뷰 데이터 하나를 원래 영어 단어로 어떻게 바꾸는지 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index는 단어와 정수 인덱스를 매핑한 딕셔너리입니다\n",
    "word_index = imdb.get_word_index()\n",
    "# 정수 인덱스와 단어를 매핑하도록 뒤집습니다\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 리뷰를 디코딩합니다. \n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "신경망에 숫자 리스트를 주입할 수는 없습니다. 리스트를 텐서로 바꾸는 두 가지 방법이 있습니다:\n",
    "\n",
    "* 같은 길이가 되도록 리스트에 패딩을 추가하고 `(samples, sequence_length)` 크기의 정수 텐서로 변환합니다. 그다음 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용합니다(`Embedding` 층을 말하며 나중에 자세히 다루겠습니다).\n",
    "* 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환합니다. 예를 들면 시퀀스 `[3, 5]`를 인덱스 3과 5의 위치는 1이고 그 외는 모두 0인 10,000차원의 벡터로 각각 변환합니다. 그다음 부동 소수 벡터 데이터를 다룰 수 있는 `Dense` 층을 신경망의 첫 번째 층으로 사용합니다.\n",
    "\n",
    "여기서는 두 번째 방식을 사용하고 이해를 돕기 위해 직접 데이터를 원-핫 벡터로 만들겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터를 벡터로 변환합니다\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터를 벡터로 변환합니다\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 샘플은 다음과 같이 나타납니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블은 쉽게 벡터로 바꿀 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블을 벡터로 바꿉니다\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망에 주입할 데이터가 준비되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 모델 만들기\n",
    "\n",
    "입력 데이터가 벡터이고 레이블은 스칼라(1 또는 0)입니다. 아마 앞으로 볼 수 있는 문제 중에서 가장 간단할 것입니다. 이런 문제에 잘 작동하는 네트워크 종류는 `relu` 활성화 함수를 사용한 완전 연결 층(즉, `Dense(16, activation='relu')`)을 그냥 쌓은 것입니다.\n",
    "\n",
    "`Dense` 층에 전달한 매개변수(16)는 은닉 유닛의 개수입니다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 됩니다. 2장에서 `relu` 활성화 함수를 사용한 `Dense` 층을 다음과 같은 텐서 연산을 연결하여 구현하였습니다:\n",
    "\n",
    "`output = relu(dot(W, input) + b)`\n",
    "\n",
    "16개의 은닉 유닛이 있다는 것은 가중치 행렬 `W`의 크기가 `(input_dimension, 16)`이라는 뜻입니다. 입력 데이터와 `W`를 점곱하면 입력 데이터가 16 차원으로 표현된 공간으로 투영됩니다(그리고 편향 벡터 `b`를 더하고 `relu` 연산을 적용합니다). 표현 공간의 차원을 '신경망이 내재된 표현을 학습할 때 가질 수 있는 자유도'로 이해할 수 있습니다. 은닉 유닛을 늘리면 (표현 공간을 더 고차원으로 만들면) 신경망이 더욱 복잡한 표현을 학습할 수 있지만 계산 비용이 커지고 원치 않은 패턴을 학습할 수도 있습니다(훈련 데이터에서는 성능이 향상되지만 테스트 데이터에서는 그렇지 않은 패턴입니다).\n",
    "\n",
    "`Dense` 층을 쌓을 때 두 가진 중요한 구조상의 결정이 필요합니다:\n",
    "\n",
    "* 얼마나 많은 층을 사용할 것인가\n",
    "* 각 층에 얼마나 많은 은닉 유닛을 둘 것인가\n",
    "\n",
    "4장에서 이런 결정을 하는 데 도움이 되는 일반적인 원리를 배우겠습니다. 당분간은 저를 믿고 선택한 다음 구조를 따라 주세요.\n",
    "\n",
    "* 16개의 은닉 유닛을 가진 두 개의 은닉층\n",
    "* 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층\n",
    "\n",
    "중간에 있는 은닉층은 활성화 함수로 `relu`를 사용하고 마지막 층은 확률(0과 1 사이의 점수로, 어떤 샘플이 타깃 '1'일 가능성이 높다는 것은 그 리뷰가 긍정일 가능성이 높다는 것을 의미합니다)을 출력하기 위해 시그모이드 활성화 함수를 사용합니다. `relu`는 음수를 0으로 만드는 함수입니다. 시그모이드는 임의의 값을 [0, 1] 사이로 압축하므로 출력 값을 확률처럼 해석할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음이 이 신경망의 모습입니다:\n",
    "\n",
    "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 이 신경망의 케라스 구현입니다. 이전에 보았던 MNIST 예제와 비슷합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 손실 함수와 옵티마이저를 선택해야 합니다. 이진 분류 문제이고 신경망의 출력이 확률이기 때문에(네트워크의 끝에 시그모이드 활성화 함수를 사용한 하나의 유닛으로 된 층을 놓았습니다), `binary_crossentropy` 손실이 적합합니다. 이 함수가 유일한 선택은 아니고 예를 들어 `mean_squared_error`를 사용할 수도 있습니다. 확률을 출력하는 모델을 사용할 때는 크로스엔트로피가 최선의 선택입니다. 크로스엔트로피는 정보 이론 분야에서 온 개념으로 확률 분포 간의 차이를 측정합니다. 여기에서는 원본 분포와 예측 분포 사이를 측정합니다.\n",
    "\n",
    "다음은 `rmsprop` 옵티마이저와 `binary_crossentropy` 손실 함수로 모델을 설정하는 단계입니다. 훈련하는 동안 정확도를 사용해 모니터링하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에 `rmsprop`, `binary_crossentropy`, `accuracy`가 포함되어 있기 때문에 옵티마이저, 손실 함수, 측정 지표를 문자열로 지정하는 것이 가능합니다. 이따금 옵티마이저의 매개변수를 바꾸거나 자신만의 손실 함수, 측정 함수를 전달해야 할 경우가 있습니다. 전자의 경우에는 옵티마이저 파이썬 클래스를 사용해 객체를 직접 만들어 `optimizer` 매개변수에 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후자의 경우는 `loss`와 `metrics` 매개변수에 함수 객체를 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련하는 동안 처음 본 데이터에 대한 모델의 정확도를 측정하기 위해서는 원본 훈련 데이터에서 10,000의 샘플을 떼어서 검증 세트를 만들어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이제 모델을 512개 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련시킵니다(`x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 20번 반복합니다). 동시에 따로 떼어 놓은 10,000개의 샘플에서 손실과 정확도를 측정할 것입니다. 이렇게 하려면 `validation_data` 매개변수에 검증 데이터를 전달해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.6884 - val_acc: 0.8639\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s 107us/step - loss: 0.0045 - acc: 0.9993 - val_loss: 0.7184 - val_acc: 0.8656\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 2s 108us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7447 - val_acc: 0.8650\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.7796 - val_acc: 0.8640\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 8.0560e-04 - acc: 1.0000 - val_loss: 0.7994 - val_acc: 0.8637\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 119us/step - loss: 6.6771e-04 - acc: 1.0000 - val_loss: 0.8429 - val_acc: 0.8591\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.8615 - val_acc: 0.8636\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 3.3912e-04 - acc: 1.0000 - val_loss: 0.8807 - val_acc: 0.8635\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 107us/step - loss: 2.7457e-04 - acc: 1.0000 - val_loss: 0.9126 - val_acc: 0.8607\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s 107us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.9504 - val_acc: 0.8612\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 1.6055e-04 - acc: 1.0000 - val_loss: 0.9567 - val_acc: 0.8609\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 108us/step - loss: 1.1836e-04 - acc: 1.0000 - val_loss: 0.9722 - val_acc: 0.8602\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 8.9466e-05 - acc: 1.0000 - val_loss: 1.0071 - val_acc: 0.8595\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 0.0027 - acc: 0.9993 - val_loss: 1.0593 - val_acc: 0.8577\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 6.1031e-05 - acc: 1.0000 - val_loss: 1.0574 - val_acc: 0.8600\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 4.2323e-05 - acc: 1.0000 - val_loss: 1.0650 - val_acc: 0.8598\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 114us/step - loss: 3.2942e-05 - acc: 1.0000 - val_loss: 1.0804 - val_acc: 0.8596\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s 108us/step - loss: 2.4475e-05 - acc: 1.0000 - val_loss: 1.1102 - val_acc: 0.8592\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 5.9207e-04 - acc: 0.9997 - val_loss: 1.1287 - val_acc: 0.8603\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s 114us/step - loss: 1.2914e-05 - acc: 1.0000 - val_loss: 1.1358 - val_acc: 0.8598\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU를 사용해도 에포크마다 2초가 걸리지 않습니다. 전체 훈련은 20초 이상 걸립니다. 에포크가 끝날 때마다 10,000개의 검증 샘플 데이터에서 손실과 정확도를 계산하기 때문에 약간씩 지연됩니다.\n",
    "\n",
    "`model.fit()` 메서드는 `History` 객체를 반환합니다. 이 객체는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리인 `history` 속성을 가지고 있습니다. 한 번 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 딕셔너리는 훈련과 검증하는 동안 모니터링할 측정 지표당 하나씩 모두 네 개의 항목을 담고 있습니다. 맷플롯립을 사용해 훈련과 검증 데이터에 대한 손실과 정확도를 그려 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# ‘b’는 파란색 실선을 의미합니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "점선은 훈련 손실과 정확도이고 실선은 검증 손실과 정확도입니다. 신경망의 무작위한 초기화 때문에 사람마다 결과거 조금 다를 수 있습니다.\n",
    "\n",
    "여기에서 볼 수 있듯이 훈련 손실이 에포크마다 감소하고 훈련 정확도는 에포크마다 증가합니다. 경사 하강법 최적화를 사용했을 때 반복마다 최소화되는 것이 손실이므로 기대했던 대로입니다. 검증 손실과 정확도는 이와 같지 않습니다. 4번째 에포크에서 그래프가 역전되는 것 같습니다. 이것이 훈련 세트에서 잘 작동하는 모델이 처음 보는 데이터에 잘 작동하지 않을 수 있다고 앞서 언급한 경고의 한 사례입니다. 정확한 용어로 말하면 과대적합되었다고 합니다. 2번째 에포크 이후부터 훈련 데이터에 과도하게 최적화되어 훈련 데이터에 특화된 표현을 학습하므로 훈련 세트 이외의 데이터에는 일반화되지 못합니다.\n",
    "\n",
    "이런 경우에 과대적합을 방지하기 위해서 3번째 에포크 이후에 훈련을 중지할 수 있습니다. 일반적으로 4장에서 보게 될 과대적합을 완화하는 다양한 종류의 기술을 사용할 수 있습니다.\n",
    "\n",
    "처음부터 다시 새로운 신경망을 4번의 에포크 동안만 훈련하고 테스트 데이터에서 평가해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 0.4632 - acc: 0.8182\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 68us/step - loss: 0.2659 - acc: 0.9061\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 0.2045 - acc: 0.9273\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - ETA: 0s - loss: 0.1707 - acc: 0.939 - 2s 73us/step - loss: 0.1705 - acc: 0.9399\n",
      "25000/25000 [==============================] - 2s 99us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2901408172416687, 0.88516]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아주 단순한 방식으로도 87%의 정확도를 달성했습니다. 최고 수준의 기법을 사용하면 95%에 가까운 성능을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련된 모델로 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델을 훈련시킨 후에 이를 실전 환경에서 사용하고 싶을 것입니다. `predict` 메서드를 사용해서 어떤 리뷰가 긍정일 확률을 예측할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23341629],\n",
       "       [0.9996598 ],\n",
       "       [0.934989  ],\n",
       "       ...,\n",
       "       [0.13033345],\n",
       "       [0.06785527],\n",
       "       [0.6900388 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서처럼 이 모델은 어떤 샘플에 대해 확신을 가지고 있지만(0.99 또는 그 이상, 0.01 또는 그 이하) 어떤 샘플에 대해서는 확신이 부족합니다(0.6, 0.4). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 실험\n",
    "\n",
    "* 여기에서는 두 개의 은닉층을 사용했습니다. 한 개 또는 세 개의 은닉층을 사용하고 검증과 테스트 정확도에 어떤 영향을 미치는지 확인해 보세요.\n",
    "* 층의 은닉 유닛을 추가하거나 줄여 보세요: 32개 유닛, 64개 유닛 등\n",
    "* `binary_crossentropy` 대신에 `mse` 손실 함수를 사용해 보세요.\n",
    "* `relu` 대신에 `tanh` 활성화 함수(초창기 신경망에서 인기 있었던 함수입니다)를 사용해 보세요.\n",
    "\n",
    "다음 실험을 진행하면 여기에서 선택한 구조가 향상의 여지는 있지만 어느 정도 납득할 만한 수준이라는 것을 알게 것입니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다:\n",
    "\n",
    "* 원본 데이터를 신경망에 텐서로 주입하기 위해서는 꽤 많은 전처리가 필요합니다. 단어 시퀀스는 이진 벡터로 인코딩될 수 있고 다른 인코딩 방식도 있습니다.\n",
    "* `relu` 활성화 함수와 함께 `Dense` 층을 쌓은 네트워크는 (감성 분류를 포함하여) 여러 종류의 문제에 적용할 수 있어서 앞으로 자주 사용하게 될 것입니다.\n",
    "* (출력 클래스가 두 개인) 이진 분류 문제에서 네트워크는 하나의 유닛과 `sigmoid` 활성화 함수를 가진 `Dense` 층으로 끝나야 합니다. 이 신경망의 출력은 확률을 나타내는 0과 1 사이의 스칼라 값입니다.\n",
    "* 이진 분류 문제에서 이런 스칼라 시그모이드 출력에 대해 사용할 손실 함수는 `binary_crossentropy`입니다.\n",
    "* `rmsprop` 옵티마이저는 문제에 상관없이 일반적으로 충분히 좋은 선택입니다. 걱정할 거리가 하나 줄은 셈입니다.\n",
    "* 훈련 데이터에 대해 성능이 향상됨에 따라 신경망은 과대적합되기 시작하고 이전에 본적 없는 데이터에서는 결과가 점점 나빠지게 됩니다. 항상 훈련 세트 이외의 데이터에서 성능을 모니터링해야 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
